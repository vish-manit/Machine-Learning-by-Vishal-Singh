{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06622c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 4.96, b 1.44, cost 89.0 iteration 0\n",
      "m 0.4991999999999983, b 0.26879999999999993, cost 71.10560000000002 iteration 1\n",
      "m 4.451584000000002, b 1.426176000000001, cost 56.8297702400001 iteration 2\n",
      "m 0.892231679999997, b 0.5012275199999995, cost 45.43965675929613 iteration 3\n",
      "m 4.041314713600002, b 1.432759910400001, cost 36.35088701894832 iteration 4\n",
      "m 1.2008760606719973, b 0.7036872622079998, cost 29.097483330142282 iteration 5\n",
      "m 3.7095643080294423, b 1.4546767911321612, cost 23.307872849944438 iteration 6\n",
      "m 1.4424862661541864, b 0.881337636696883, cost 18.685758762535738 iteration 7\n",
      "m 3.4406683721083144, b 1.4879302070713722, cost 14.994867596913156 iteration 8\n",
      "m 1.6308855378034224, b 1.0383405553279617, cost 12.046787238456794 iteration 9\n",
      "m 3.2221235247119777, b 1.5293810083298451, cost 9.691269350698109 iteration 10\n",
      "m 1.7770832372205707, b 1.1780607551353204, cost 7.8084968312098315 iteration 11\n",
      "m 3.0439475772474127, b 1.5765710804477953, cost 6.302918117062937 iteration 12\n",
      "m 1.8898457226770244, b 1.3032248704973899, cost 5.098330841763168 iteration 13\n",
      "m 2.898169312926714, b 1.6275829443328358, cost 4.133961682056365 iteration 14\n",
      "m 1.9761515088959358, b 1.4160484030347593, cost 3.361340532576948 iteration 15\n",
      "m 2.7784216197824048, b 1.6809279342791488, cost 2.741808050753047 iteration 16\n",
      "m 2.0415541605113807, b 1.5183370872989306, cost 2.244528230107478 iteration 17\n",
      "m 2.6796170361078637, b 1.735457156285639, cost 1.8449036666988363 iteration 18\n",
      "m 2.090471617540917, b 1.611567833948162, cost 1.5233119201782324 iteration 19\n",
      "m 2.5976890103737853, b 1.790290604096816, cost 1.2640979056612756 iteration 20\n",
      "m 2.1264168621494517, b 1.6969533824619085, cost 1.0547704368105268 iteration 21\n",
      "m 2.529385561184701, b 1.8447607474362664, cost 0.8853615531285766 iteration 22\n",
      "m 2.1521818147302194, b 1.7754939584778073, cost 0.7479156468369821 iteration 23\n",
      "m 2.472104720735685, b 1.8983676540508527, cost 0.6360820885229722 iteration 24\n",
      "m 2.1699839382964696, b 1.8480185634495874, cost 0.5447903801652151 iteration 25\n",
      "m 2.423763296438881, b 1.950743302915348, cost 0.4699911136477278 iteration 26\n",
      "m 2.1815831093070837, b 1.9152179921582295, cost 0.4084494012702221 iteration 27\n",
      "m 2.3826922006906663, b 2.0016232209455125, cost 0.35758014655339476 iteration 28\n",
      "m 2.1883747814212473, b 1.9776712492627107, cost 0.31531667795040486 iteration 29\n",
      "m 2.3475529664737507, b 2.0508239542984783, cost 0.280005985849834 iteration 30\n",
      "m 2.19146424741668, b 2.0358666977033213, cost 0.2503251729489924 iteration 31\n",
      "m 2.317271157065729, b 2.0982251873107836, cost 0.2252148202231392 iteration 32\n",
      "m 2.19172583072087, b 2.0902190019495084, cost 0.2038258415569305 iteration 33\n",
      "m 2.2909832477163747, b 2.1437555628915694, cost 0.1854770944836773 iteration 34\n",
      "m 2.1898500615476015, b 2.1410827139250586, cost 0.16962156815305135 iteration 35\n",
      "m 2.2679942505397945, b 2.1873814501542004, cost 0.15581941113049289 iteration 36\n",
      "m 2.1863812735157397, b 2.188763177870427, cost 0.14371641365577967 iteration 37\n",
      "m 2.247743906750233, b 2.2290980581236037, cost 0.13302683968149862 iteration 38\n",
      "m 2.181747562970493, b 2.2335252935837153, cost 0.1235197278285518 iteration 39\n",
      "m 2.2297797112222417, b 2.268922416384484, cost 0.11500795886067308 iteration 40\n",
      "m 2.176284659606544, b 2.2756005683762908, cost 0.1073395295828815 iteration 41\n",
      "m 2.213735385878407, b 2.306887840824943, cost 0.10039058653754176 iteration 42\n",
      "m 2.170254943136438, b 2.315192801071317, cost 0.09405986334903649 iteration 43\n",
      "m 2.1993136987020745, b 2.3430395801944157, cost 0.08826423771269985 iteration 44\n",
      "m 2.1638625904931037, b 2.3524826719863134, cost 0.08293518155053264 iteration 45\n",
      "m 2.1862727486718105, b 2.3774314010318136, cost 0.07801592372722821 iteration 46\n",
      "m 2.1572656385141533, b 2.3876314575042543, cost 0.07345918129710392 iteration 47\n",
      "m 2.1744150151272015, b 2.4101229178167802, cost 0.06922534441882239 iteration 48\n",
      "m 2.150585587951272, b 2.4207840437050385, cost 0.06528102333197575 iteration 49\n",
      "m 2.1635786121786147, b 2.441177514495622, cost 0.06159788433500965 iteration 50\n",
      "m 2.1439150477863547, b 2.4520713783305874, cost 0.05815171649232756 iteration 51\n",
      "m 2.153630302083688, b 2.470660734860243, cost 0.054921682590988646 iteration 52\n",
      "m 2.137323817683481, b 2.4816124722824338, cost 0.05188971727120564 iteration 53\n",
      "m 2.1444599118649865, b 2.4986390442291735, cost 0.04904004275389065 iteration 54\n",
      "m 2.1308637257526066, b 2.509516039457312, cost 0.04635877856867898 iteration 55\n",
      "m 2.1359758694885094, b 2.525178884782891, cost 0.04383362645496491 iteration 56\n",
      "m 2.124572474492945, b 2.535881845863144, cost 0.04145361541183607 iteration 57\n",
      "m 2.128101633371053, b 2.5503459627684273, cost 0.03920889490609494 iteration 58\n",
      "m 2.118476696509155, b 2.5608018247073736, cost 0.03709056666678448 iteration 59\n",
      "m 2.120772834793503, b 2.5742047184297996, cost 0.03509054742420437 iteration 60\n",
      "m 2.112594380710634, b 2.5843610027801502, cost 0.03320145649050715 iteration 61\n",
      "m 2.1139349893254455, b 2.5968179395942217, cost 0.03141652330669783 iteration 62\n",
      "m 2.1069367971074353, b 2.606638274382932, cost 0.0297295110602709 iteration 63\n",
      "m 2.1075416624945413, b 2.618246487870094, cost 0.0281346532591438 iteration 64\n",
      "m 2.1015100223265035, b 2.6277070518134993, cost 0.02662660077102551 iteration 65\n",
      "m 2.101552998161378, b 2.6385491128066176, cost 0.025200377334927134 iteration 66\n",
      "m 2.096316147250177, b 2.6476358156400974, cost 0.023851341948628327 iteration 67\n",
      "m 2.095934536582619, b 2.657782334457597, cost 0.022575156852933542 iteration 68\n",
      "m 2.0913542316575633, b 2.6664885833847243, cost 0.021367760086655644 iteration 69\n",
      "m 2.090656263915584, b 2.676000378847538, cost 0.020225341788425083 iteration 70\n",
      "m 2.0866210575773376, b 2.6843253115524512, cost 0.019144323582910155 iteration 71\n",
      "m 2.0856918466960472, b 2.693255154066937, cost 0.018121340518098442 iteration 72\n",
      "m 2.082111722558874, b 2.7012022430021245, cost 0.017153225123473996 iteration 73\n",
      "m 2.0810180142142363, b 2.709596257293525, cost 0.01623699324146153 iteration 74\n",
      "m 2.077820105696288, b 2.717172209303728, cost 0.015369831350564987 iteration 75\n",
      "m 2.0766140592050317, b 2.7250710050809133, cost 0.014549085151541019 iteration 76\n",
      "m 2.0737392325653374, b 2.732284895849552, cost 0.013772249230347736 iteration 77\n",
      "m 2.0724614332425584, b 2.7397244808822614, cost 0.013036957645638886 iteration 78\n",
      "m 2.0698615599121704, b 2.7465870759846718, cost 0.012340975315898037 iteration 79\n",
      "m 2.0685434179941087, b 2.7535995950692826, cost 0.011682190103287127 iteration 80\n",
      "m 2.066179196691222, b 2.760122819221025, cost 0.011058605508984853 iteration 81\n",
      "m 2.064844857288579, b 2.7667371537338745, cost 0.010468333909073289 iteration 82\n",
      "m 2.0626840746684203, b 2.7729336776379365, cost 0.009909590271584152 iteration 83\n",
      "m 2.061351937985791, b 2.7791759333750248, cost 0.009380686304666458 iteration 84\n",
      "m 2.0593680791107873, b 2.785058853801841, cost 0.00888002499345325 iteration 85\n",
      "m 2.0580520100509183, b 2.7909527592203687, cost 0.00840609548939642 iteration 86\n",
      "m 2.056223147935525, b 2.7965353529206687, cost 0.007957468320912865 iteration 87\n",
      "m 2.05493343816708, b 2.8021025854443096, cost 0.007532790898352296 iteration 88\n",
      "m 2.0532413459797505, b 2.8073981214530215, cost 0.007130783289727114 iteration 89\n",
      "m 2.0519854787579397, b 2.812658575950258, cost 0.0067502342464980354 iteration 90\n",
      "m 2.050414919687842, b 2.8176801739944057, cost 0.006389997461079277 iteration 91\n",
      "m 2.0491981775199255, b 2.8226521847051367, cost 0.006048988039717134 iteration 92\n",
      "m 2.047736336426391, b 2.8274127099427506, cost 0.005726179176078216 iteration 93\n",
      "m 2.0465622835434223, b 2.8321132348672426, cost 0.005420599012302664 iteration 94\n",
      "m 2.045198311770722, b 2.836625221187641, cost 0.005131327675503935 iteration 95\n",
      "m 2.0440691768841837, b 2.8410699961476715, cost 0.0048574944787420265 iteration 96\n",
      "m 2.042793827417138, b 2.845345591859636, cost 0.004598275276411798 iteration 97\n",
      "m 2.0417108070703494, b 2.8495492600018677, cost 0.004352889964781892 iteration 98\n",
      "m 2.0405161418256377, b 2.8536001910078013, cost 0.004120600119124239 iteration 99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(x,y):\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 100\n",
    "    n = len(x)\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
    "        md = -(2/n)*sum(x*(y-y_predicted))\n",
    "        bd = -(2/n)*sum(y-y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        print (\"m {}, b {}, cost {} iteration {}\".format(m_curr,b_curr,cost, i))\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([5,7,9,11,13])\n",
    "\n",
    "gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef80c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a6bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>david</td>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laura</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanjay</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wei</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jeff</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamir</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>venkat</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>virat</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arthur</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paul</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  math  cs\n",
       "0   david    92  98\n",
       "1   laura    56  68\n",
       "2  sanjay    88  81\n",
       "3     wei    70  80\n",
       "4    jeff    80  83\n",
       "5   aamir    49  52\n",
       "6  venkat    65  66\n",
       "7   virat    35  30\n",
       "8  arthur    66  68\n",
       "9    paul    67  73"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Exercise4.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f6ab76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   math  cs\n",
       "0    92  98\n",
       "1    56  68\n",
       "2    88  81\n",
       "3    70  80\n",
       "4    80  83\n",
       "5    49  52\n",
       "6    65  66\n",
       "7    35  30\n",
       "8    66  68\n",
       "9    67  73"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('name' , axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab40906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(df[['math']],df.cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26020f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01773624])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc193a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9152193111569176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c16913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 0.8902620000000001, b 0.012582000000000001, cost 5199.1 iteration 0\n",
      "m 1.021762658592, b 0.014457224952, cost 144.5535068456823 iteration 1\n",
      "m 1.0411864282797623, b 0.014750948444598433, cost 34.271679164278495 iteration 2\n",
      "m 1.0440552836099133, b 0.014811067660242544, cost 31.865508353169123 iteration 3\n",
      "m 1.0444788070626871, b 0.014836680937938102, cost 31.81300550544398 iteration 4\n",
      "m 1.0445411297368326, b 0.014857197159247524, cost 31.811855790128114 iteration 5\n",
      "m 1.04455009932684, b 0.014876960319803186, cost 31.811826515098904 iteration 6\n",
      "m 1.0445511881175678, b 0.014896612072639698, cost 31.811821686305475 iteration 7\n",
      "m 1.0445511128352645, b 0.014916247196540989, cost 31.811817390974994 iteration 8\n",
      "m 1.0445508656097877, b 0.014935879691314392, cost 31.81181310737033 iteration 9\n",
      "m 1.0445505929889671, b 0.01495551162487787, cost 31.81180882410807 iteration 10\n",
      "m 1.044550316619431, b 0.014975143302686051, cost 31.811804540939903 iteration 11\n",
      "m 1.0445500396986098, b 0.01499477476985953, cost 31.81180025786031 iteration 12\n",
      "m 1.0445497626987976, b 0.01501440603306487, cost 31.811795974869213 iteration 13\n",
      "m 1.0445494856897566, b 0.015034037093288575, cost 31.811791691966633 iteration 14\n",
      "m 1.0445492086817916, b 0.01505366795067815, cost 31.81178740915256 iteration 15\n",
      "m 1.0445489316764243, b 0.015073298605257166, cost 31.811783126426963 iteration 16\n",
      "m 1.04454865467388, b 0.015092929057030894, cost 31.811778843789824 iteration 17\n",
      "m 1.0445483776741915, b 0.015112559306001895, cost 31.811774561241226 iteration 18\n",
      "m 1.044548100677364, b 0.015132189352172335, cost 31.811770278781047 iteration 19\n",
      "m 1.044547823683398, b 0.015151819195544319, cost 31.811765996409395 iteration 20\n",
      "m 1.0445475466922938, b 0.015171448836119945, cost 31.811761714126227 iteration 21\n",
      "m 1.044547269704051, b 0.015191078273901303, cost 31.811757431931557 iteration 22\n",
      "m 1.0445469927186697, b 0.015210707508890491, cost 31.811753149825307 iteration 23\n",
      "m 1.04454671573615, b 0.015230336541089608, cost 31.81174886780758 iteration 24\n",
      "m 1.0445464387564918, b 0.015249965370500742, cost 31.81174458587831 iteration 25\n",
      "m 1.0445461617796952, b 0.015269593997125994, cost 31.811740304037542 iteration 26\n",
      "m 1.0445458848057598, b 0.015289222420967457, cost 31.811736022285217 iteration 27\n",
      "m 1.0445456078346862, b 0.015308850642027227, cost 31.81173174062135 iteration 28\n",
      "m 1.0445453308664736, b 0.015328478660307395, cost 31.811727459045983 iteration 29\n",
      "m 1.0445450539011225, b 0.01534810647581006, cost 31.81172317755906 iteration 30\n",
      "m 1.044544776938633, b 0.015367734088537317, cost 31.811718896160603 iteration 31\n",
      "m 1.0445444999790043, b 0.015387361498491257, cost 31.811714614850604 iteration 32\n",
      "m 1.0445442230222373, b 0.01540698870567398, cost 31.81171033362908 iteration 33\n",
      "m 1.0445439460683315, b 0.015426615710087577, cost 31.811706052496007 iteration 34\n",
      "m 1.044543669117287, b 0.015446242511734144, cost 31.811701771451403 iteration 35\n",
      "m 1.0445433921691034, b 0.015465869110615774, cost 31.811697490495238 iteration 36\n",
      "m 1.044543115223781, b 0.015485495506734564, cost 31.811693209627528 iteration 37\n",
      "m 1.0445428382813198, b 0.015505121700092609, cost 31.811688928848266 iteration 38\n",
      "m 1.0445425613417196, b 0.015524747690692004, cost 31.811684648157446 iteration 39\n",
      "m 1.0445422844049808, b 0.015544373478534842, cost 31.81168036755511 iteration 40\n",
      "m 1.0445420074711027, b 0.015563999063623216, cost 31.811676087041178 iteration 41\n",
      "m 1.0445417305400855, b 0.015583624445959223, cost 31.811671806615717 iteration 42\n",
      "m 1.0445414536119297, b 0.015603249625544964, cost 31.811667526278683 iteration 43\n",
      "m 1.0445411766866346, b 0.015622874602382524, cost 31.811663246030083 iteration 44\n",
      "m 1.0445408997642005, b 0.015642499376474, cost 31.81165896586993 iteration 45\n",
      "m 1.0445406228446272, b 0.015662123947821488, cost 31.811654685798217 iteration 46\n",
      "m 1.044540345927915, b 0.01568174831642708, cost 31.81165040581493 iteration 47\n",
      "m 1.0445400690140634, b 0.015701372482292874, cost 31.811646125920113 iteration 48\n",
      "m 1.0445397921030726, b 0.01572099644542096, cost 31.81164184611368 iteration 49\n",
      "m 1.0445395151949426, b 0.01574062020581344, cost 31.811637566395685 iteration 50\n",
      "m 1.0445392382896734, b 0.015760243763472404, cost 31.81163328676614 iteration 51\n",
      "m 1.0445389613872649, b 0.015779867118399946, cost 31.811629007224997 iteration 52\n",
      "m 1.0445386844877171, b 0.01579949027059816, cost 31.81162472777228 iteration 53\n",
      "m 1.04453840759103, b 0.015819113220069143, cost 31.811620448408004 iteration 54\n",
      "m 1.0445381306972035, b 0.015838735966814985, cost 31.81161616913214 iteration 55\n",
      "m 1.0445378538062375, b 0.015858358510837785, cost 31.811611889944665 iteration 56\n",
      "m 1.044537576918132, b 0.015877980852139633, cost 31.81160761084563 iteration 57\n",
      "m 1.0445373000328873, b 0.01589760299072263, cost 31.811603331835045 iteration 58\n",
      "m 1.044537023150503, b 0.015917224926588862, cost 31.81159905291282 iteration 59\n",
      "m 1.0445367462709791, b 0.01593684665974043, cost 31.811594774078994 iteration 60\n",
      "m 1.0445364693943158, b 0.015956468190179422, cost 31.81159049533364 iteration 61\n",
      "m 1.0445361925205126, b 0.015976089517907938, cost 31.81158621667663 iteration 62\n",
      "m 1.0445359156495702, b 0.01599571064292807, cost 31.81158193810805 iteration 63\n",
      "m 1.044535638781488, b 0.016015331565241913, cost 31.811577659627886 iteration 64\n",
      "m 1.044535361916266, b 0.01603495228485156, cost 31.811573381236123 iteration 65\n",
      "m 1.0445350850539044, b 0.016054572801759103, cost 31.81156910293275 iteration 66\n",
      "m 1.044534808194403, b 0.01607419311596664, cost 31.81156482471779 iteration 67\n",
      "m 1.0445345313377619, b 0.016093813227476262, cost 31.811560546591195 iteration 68\n",
      "m 1.044534254483981, b 0.01611343313629007, cost 31.81155626855302 iteration 69\n",
      "m 1.0445339776330604, b 0.01613305284241015, cost 31.811551990603217 iteration 70\n",
      "m 1.044533700785, b 0.016152672345838597, cost 31.811547712741806 iteration 71\n",
      "m 1.0445334239397994, b 0.016172291646577505, cost 31.811543434968815 iteration 72\n",
      "m 1.044533147097459, b 0.016191910744628973, cost 31.811539157284194 iteration 73\n",
      "m 1.0445328702579788, b 0.016211529639995094, cost 31.811534879687958 iteration 74\n",
      "m 1.0445325934213587, b 0.01623114833267796, cost 31.81153060218012 iteration 75\n",
      "m 1.0445323165875984, b 0.01625076682267966, cost 31.811526324760617 iteration 76\n",
      "m 1.0445320397566982, b 0.016270385110002294, cost 31.811522047429545 iteration 77\n",
      "m 1.044531762928658, b 0.016290003194647955, cost 31.811517770186825 iteration 78\n",
      "m 1.0445314861034773, b 0.016309621076618736, cost 31.81151349303251 iteration 79\n",
      "m 1.044531209281157, b 0.01632923875591673, cost 31.811509215966524 iteration 80\n",
      "m 1.0445309324616963, b 0.016348856232544035, cost 31.811504938988936 iteration 81\n",
      "m 1.0445306556450955, b 0.01636847350650274, cost 31.811500662099686 iteration 82\n",
      "m 1.0445303788313545, b 0.01638809057779494, cost 31.811496385298867 iteration 83\n",
      "m 1.0445301020204734, b 0.016407707446422733, cost 31.81149210858638 iteration 84\n",
      "m 1.0445298252124517, b 0.016427324112388206, cost 31.811487831962246 iteration 85\n",
      "m 1.04452954840729, b 0.01644694057569346, cost 31.81148355542651 iteration 86\n",
      "m 1.0445292716049879, b 0.016466556836340577, cost 31.811479278979107 iteration 87\n",
      "m 1.0445289948055454, b 0.01648617289433166, cost 31.81147500262008 iteration 88\n",
      "m 1.0445287180089626, b 0.016505788749668803, cost 31.811470726349384 iteration 89\n",
      "m 1.0445284412152394, b 0.016525404402354095, cost 31.811466450167075 iteration 90\n",
      "m 1.0445281644243756, b 0.016545019852389632, cost 31.811462174073103 iteration 91\n",
      "m 1.0445278876363715, b 0.01656463509977751, cost 31.811457898067484 iteration 92\n",
      "m 1.044527610851227, b 0.016584250144519818, cost 31.811453622150225 iteration 93\n",
      "m 1.0445273340689418, b 0.01660386498661865, cost 31.81144934632132 iteration 94\n",
      "m 1.044527057289516, b 0.016623479626076104, cost 31.81144507058075 iteration 95\n",
      "m 1.0445267805129497, b 0.01664309406289427, cost 31.81144079492849 iteration 96\n",
      "m 1.0445265037392426, b 0.01666270829707524, cost 31.811436519364634 iteration 97\n",
      "m 1.044526226968395, b 0.016682322328621116, cost 31.8114322438891 iteration 98\n",
      "m 1.044525950200407, b 0.016701936157533983, cost 31.811427968501874 iteration 99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(x,y):\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 100\n",
    "    n = len(x)\n",
    "    learning_rate =0.00009\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
    "        md = -(2/n)*sum(x*(y-y_predicted))\n",
    "        bd = -(2/n)*sum(y-y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        print (\"m {}, b {}, cost {} iteration {}\".format(m_curr,b_curr,cost, i))\n",
    "\n",
    "x = np.array([92,56,88,70,80,49,65,35,66,67])\n",
    "y = np.array([98,68,81,80,83,52,66,30,68,73])\n",
    "\n",
    "gradient_descent(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
